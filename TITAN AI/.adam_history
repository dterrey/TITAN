exit
exit
exit
what is ef8b4e8c58ad596b28d6475370c36718b4d80e6c34cc27ff765fd2868efc64f6
exit
search for iocs in timesketch
show me 4624 events
exit
show me 4624 events
exit
show me 4624 events
exit
show me 4624 events
exit
show me 4624 events
exit
show me all 4624 events
show me all 4625 events
exit
codex hash
exit
codex hash
exit
codex hash
5ff465afaabcbf0150d1a3ab2c2e74f3a4426467
codex hash
5ff465afaabcbf0150d1a3ab2c2e74f3a4426467
y
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for iocs in timesketch
exit
search for iocs in timesketch
exit
search for iocs in timesketch
exit
search for iocs in timesketch
exit
search for iocs in timesketch
exit
search for iocs in timesketch
exit
search for iocs in timesketch
exit
search for iocs in timesketch
exit
search for iocs in timesketch
exit
search for iocs in timesketch
exit
search for iocs in timesketch
exit
upload /home/triagex/Downloads/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for iocs in timesketch
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
exit
search for iocs in timesketch
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for iocs in timesketch
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for iocs in timesketch
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for iocs in timesketch
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
exit
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for iocs in timesketch
exit
search for iocs in timesketch
show me all 4624 events
exit
show all 4624 events
search for iocs in timesketch
exit
show me all 4624 events
exit
show me all 4624 events
search for iocs in timesketch
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for iocs in timesketch
exit
show me all 4624 events
search for iocs in timesketch
show me all 4624 events
search for iocs in timesketch
show me all 4624 events
search for iocs in timesketch
exit
show me all 4624 events
exit
show me all 4624 events
show me 4624 events
exit
show me all 4624 events
event 4624
show me all 4624 events
exit
show me all 4624 events
exit
show me all 4624 events
exit
show me all 4624 events
search for iocs in timesketch
exit
search for iocs in timesketch
show me all 4624 events
search for iocs in timesketch
show me all 4624 events
exit
show me all 4624 events
show me 4624 events
exit
event 4624
show me 4624 events
show me all 4624 events
exit
show me all 4624 events
show me 4624 events
search for all iocs
search for all iocs in timesketch
exit
search for iocs in timesketch
import os
import re
import json
import pandas as pd
import spacy
import requests
import time
from urllib.parse import urlparse
from timesketch_api_client import client, search
from IPython.display import display
import PyPDF2
import docx
import openpyxl
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer as SumyTokenizer
from sumy.summarizers.lsa import LsaSummarizer
import nltk
from rich.console import Console
from rich.text import Text
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import logging
import readline
import urllib.parse
# Import the CodexGigasInfo class for Codex operations
from codex import CodexGigasInfo
# Initialize Codex
cg = CodexGigasInfo()
# Download the required NLTK data files
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')
# Load spaCy model for NLU
nlp = spacy.load("en_core_web_sm")
# Initialize console for styled text output
console = Console()
# Initialize export folder variable
export_folder = "/home/triagex/Downloads/ADAM"
# File to store all extracted IOCs persistently
iocs_storage_file = '/home/triagex/Downloads/ADAM/iocs_storage.json'
# API Key for URLScan.io
API_KEY = "71999b57-0017-4055-956f-a38e8a8710a7"
# Initialize storage for uploaded data and active mode
uploaded_data = pd.DataFrame()
uploaded_text = ""
active_mode = "timesketch"
# Connect to Timesketch
ts_client = client.TimesketchApi('http://localhost', username='triagex', password='admin')
sketch_id = 4  # Replace with your sketch ID
sketch = ts_client.get_sketch(sketch_id)
# Load predefined questions
def load_predefined_questions(filepath):
    with open(filepath, 'r') as file:
        data = json.load(file)
    return data
predefined_questions = load_predefined_questions('/home/triagex/Downloads/ADAM/predefined_questions.json')
# Load event descriptions
def load_event_descriptions(filepath):
    with open(filepath, 'r') as file:
        event_descriptions = json.load(file)
    return event_descriptions
event_descriptions = load_event_descriptions('/home/triagex/Downloads/ADAM/event_descriptions.json')
# Function to ensure directory exists
def ensure_directory_exists(path):
    directory = os.path.dirname(path)
    if not os.path.exists(directory):
        os.makedirs(directory)
# Function to set the export folder
def set_export_folder(path):
    global export_folder
    if os.path.isdir(path):
        export_folder = path
        console.print(f"Export folder set to: {export_folder}", style="bold green")
    else:
        console.print(f"Invalid folder path: {path}. Please provide a valid folder.", style="bold red")
# Function to find the most relevant predefined question using similarity
def match_question(user_question):
    questions = [q['question'] for q in predefined_questions['questions']]
    vectorizer = TfidfVectorizer().fit_transform(questions + [user_question])
    vectors = vectorizer.toarray()
    cosine_similarities = cosine_similarity(vectors[-1:], vectors[:-1])
    best_match_index = cosine_similarities.argmax()
    best_match_score = cosine_similarities[0][best_match_index]
    if best_match_score > 0.5:  # Threshold for matching
        return predefined_questions['questions'][best_match_index]
    return None
# Function to extract data from the message field in events
def extract_data_from_message(messages, pattern):
    return messages.apply(lambda x: re.findall(pattern, x)).explode().value_counts().to_dict()
# Load IOCs from the persistent storage file
def load_iocs():
    if os.path.exists(iocs_storage_file):
        if os.stat(iocs_storage_file).st_size == 0:
            # If the file is empty, return an empty structure
            return {
                "hashes": [],
                "ips": [],
                "domains": [],
                "tools": [],
                "commands": []
            }
        with open(iocs_storage_file, 'r') as file:
            return json.load(file)
    return {
        "hashes": [],
        "ips": [],
        "domains": [],
        "tools": [],
        "commands": []
    }
# Save IOCs to the persistent storage file
def save_iocs(iocs):
    with open(iocs_storage_file, 'w') as file:
        json.dump(iocs, file, indent=4)
# Add new IOCs to storage and save
def update_iocs(new_iocs):
    iocs = load_iocs()
    for key in iocs.keys():
        iocs[key].extend(new_iocs[key])
        iocs[key] = list(set(iocs[key]))  # Remove duplicates
    save_iocs(iocs)
# Function to update IOCs and save them to the persistent storage
def update_iocs(new_iocs):
    iocs = load_iocs()
    for key in iocs.keys():
        iocs[key].extend(new_iocs[key])
        iocs[key] = list(set(iocs[key]))  # Remove duplicates
    save_iocs(iocs)
# Function to normalize paths
def normalize_path(path):
    # Replace double backslashes with single backslashes
    path = path.replace('\\\\', '\\')
    # Replace user-specific paths with a wildcard using raw string notation
    path = re.sub(r'c:\\users\\[^\\]+\\', r'c:\\users\\*\\', path, flags=re.IGNORECASE)
    return path
# Extract indicators from the text or data
def extract_indicators(text, indicator_type=None):
    indicators = {
        "hashes": [],
        "ips": [],
        "domains": [],
        "tools": [],
        "commands": []
    }
    # Regex patterns for extracting indicators
    hash_pattern = r'\b[A-Fa-f0-9]{64}\b'
    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    domain_pattern = r'\b(?:[a-zA-Z0-9-]+\.)+[a-zA-Z]{2,}\b'
    command_line_pattern = r'"command_line":\s*"([^"]+)"'  # Updated pattern to capture actual command lines
    # Extracting indicators
    indicators["hashes"] = re.findall(hash_pattern, text)
    indicators["ips"] = re.findall(ip_pattern, text)
    indicators["domains"] = re.findall(domain_pattern, text)
    # Extract tools and commands based on known keywords
    tools_keywords = ["AdFind", "Mimikatz", "RClone", "WinRAR", "PowerShell", "Ngrok"]
    for keyword in tools_keywords:
        if keyword.lower() in text.lower():
            indicators["tools"].append(keyword)
    # Extract and normalize command lines
    command_lines = re.findall(command_line_pattern, text)
    for cmd in command_lines:
        normalized_cmd = normalize_path(cmd)
        indicators["commands"].append(normalized_cmd)
    # Extract filenames from paths and normalize them
    file_path_pattern = r'\b[A-Za-z]:\\(?:[^\\/:*?"<>|\r\n]+\\)*[^\\/:*?"<>|\r\n]+\b'
    file_paths = re.findall(file_path_pattern, text)
    for path in file_paths:
        filename = normalize_path(path)  # Normalize the entire path
        indicators["commands"].append(filename)
    # Update persistent IOCs storage
    update_iocs(indicators)
    if indicator_type:
        return {indicator_type: indicators[indicator_type]}
    
    return indicators
    
# Function to extract text from PDF
def extract_text_from_pdf(file_path):
    with open(file_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        text = ""
        for page in reader.pages:
            text += page.extract_text()
    return text
# Function to extract text from DOCX
def extract_text_from_docx(file_path):
    doc = docx.Document(file_path)
    return "\n".join([para.text for para in doc.paragraphs])
# Function to summarize text
def summarize_text(text):
    parser = PlaintextParser.from_string(text, SumyTokenizer("english"))
    summarizer = LsaSummarizer()
    summary = summarizer(parser.document, 6)  # Summarize to 6 sentences
    return " ".join([str(sentence) for sentence in summary])
# Function to upload and analyze a file
def upload_and_analyze_file(file_path):
    global uploaded_data, uploaded_text, active_mode
    
    # Reset previous data
    uploaded_data = pd.DataFrame()
    uploaded_text = ""
    
    # Handle different file types
    if file_path.endswith('.csv'):
        uploaded_data = pd.read_csv(file_path)
        console.print(f"CSV file '{file_path}' uploaded.", style="bold green")
        console.print(uploaded_data.head())
        # Extract IOCs from the single-column CSV and update storage
        extract_and_store_iocs_from_csv(uploaded_data)
    elif file_path.endswith('.json'):
        with open(file_path, 'r') as file:
            data = json.load(file)
            uploaded_data = pd.json_normalize(data)
            uploaded_text = json.dumps(data)
        console.print(f"JSON file '{file_path}' uploaded.", style="bold green")
        iocs = extract_indicators(uploaded_text)
        console.print(iocs, style="bold cyan")
    elif file_path.endswith('.pdf'):
        uploaded_text = extract_text_from_pdf(file_path)
        console.print(f"PDF file '{file_path}' uploaded and summarized.", style="bold green")
    elif file_path.endswith('.docx'):
        uploaded_text = extract_text_from_docx(file_path)
        console.print(f"Word document '{file_path}' uploaded and summarized.", style="bold green")
    elif file_path.endswith('.xlsx'):
        uploaded_data = pd.read_excel(file_path)
        console.print(f"Excel file '{file_path}' uploaded.", style="bold green")
        console.print(uploaded_data.head())
    else:
        console.print("Unsupported file format. Please upload a CSV, JSON, PDF, DOCX, or XLSX file.", style="bold red")
        return
    
    # Set mode to file
    active_mode = "file"
    # Generate and print a summary for text-based files
    if uploaded_text:
        summary = summarize_text(uploaded_text)
        console.print("\nSummary of the uploaded document:\n", style="bold blue")
        console.print(summary, style="cyan")
def create_safe_folder_name(url):
    # Parse the URL to get the domain
    parsed_url = urlparse(url)
    # Use only the netloc (domain) and path, replacing unsafe characters
    safe_name = re.sub(r'[^\w\-_\. ]', '_', parsed_url.netloc + parsed_url.path)
    return safe_name
# Function to identify the root cause and sequence of events based on MITRE ATT&CK techniques
def identify_root_cause(events):
    # Sort events by timestamp
    events.sort(key=lambda x: x.get('timestamp', ''))
    
    # Initialize variables
    root_cause = None
    attack_sequence = []
    initial_compromise_event = None
    
    for event in events:
        # Directly use the MITRE ATT&CK technique from the tags
        technique = event.get('tag', [])
        if technique:
            attack_sequence.append((event, technique))
            
            # Use the first technique as the initial compromise event
            if not initial_compromise_event:
                initial_compromise_event = event
    
    if initial_compromise_event:
        root_cause = f"The attack likely began with a technique related to {initial_compromise_event['tag']} on {initial_compromise_event['timestamp']}."
    
    return root_cause, attack_sequence
# Function to generate and display root cause hypotheses
def generate_root_cause_hypothesis(events):
    root_cause, attack_sequence = identify_root_cause(events)
    
    if root_cause:
        console.print("\nRoot Cause Hypothesis:", style="bold magenta")
        console.print(root_cause, style="cyan")
        
        console.print("\nAttack Sequence:", style="bold magenta")
        for event, technique in attack_sequence:
            console.print(f"{event.get('timestamp', 'Unknown time')}: {event.get('message', 'No message')} (Technique: {', '.join(technique)})", style="cyan")
    else:
        console.print("No root cause identified.", style="bold red")
# Function to query Timesketch for events tagged with MITRE ATT&CK techniques
def query_timesketch_for_mitre_attack():
    query = 'tag:"mitre.attack.*"'  # Adjusted to search for any tag that starts with "mitre.attack"
    search_obj = search.Search(sketch=sketch)
    search_obj.query_string = query
    search_results = search_obj.table
    events_df = pd.DataFrame(search_results)
    if not events_df.empty:
        console.print("Events tagged with MITRE ATT&CK techniques found:", style="bold green")
        console.print(events_df.head(5), style="cyan")
    else:
        console.print("No events tagged with MITRE ATT&CK techniques found in Timesketch.", style="bold red")
    
    return events_df
# Function to interpret the user question and map it to a Timesketch query, Codex query, file query, or URLScan.io query
def interpret_question(question):
    global active_mode, export_folder
    if question.lower().startswith("set export"):
        path = question[10:].strip()
        set_export_folder(path)
        return None, None, "info", None
    csv_filename = None
    if "export to" in question:
        parts = question.split("export to")
        question = parts[0].strip()
        csv_filename = parts[1].strip()
    # Handle Codex file or hash queries
    if "codex file" in question.lower():
        file_path = input("Please enter the full path to the file for Codex analysis: ").strip()
        send_file_and_get_report(file_path)
        return None, None, "codex", None
    elif "codex hash" in question.lower():
        file_hash = input("Please enter the file hash (MD5, SHA1, or SHA256) for Codex analysis: ").strip()
        process_hash(file_hash)
        return None, None, "codex", None
    # Handle URLScan.io queries
    if "scan url" in question.lower():
        url = re.search(r'scan url\s+(\S+)', question, re.IGNORECASE)
        if url:
            url = url.group(1)
            scan_id = scan_url(url)
            if scan_id:
                console.print("Waiting for scan results...", style="bold yellow")
                scan_data = get_scan_results(scan_id)
                if scan_data:
                    folder_name = create_safe_folder_name(url)
                    folder_path = os.path.join('/home/triagex/Downloads/ADAM/url', folder_name)
                    os.makedirs(folder_path, exist_ok=True)
                    display_results(scan_data)
                    export_results_to_csv(scan_data, folder_path)
                    save_results_to_json(scan_data, folder_path)
                    save_screenshot(scan_data, folder_path)
                    download_all_responses(scan_data, folder_path)
            return None, None, "urlscan", None
    # Handle IOC search in Timesketch (with chunking)
    if "search for iocs in timesketch" in question.lower():
        iocs = load_iocs()
        query_parts = []
        if iocs['hashes']:
            query_parts.append(f" OR ".join([f"message:{ioc}" for ioc in iocs['hashes']]))
        if iocs['ips']:
            query_parts.append(f" OR ".join([f"message:{ioc}" for ioc in iocs['ips']]))
        if iocs['domains']:
            query_parts.append(f" OR ".join([f"message:{ioc}" for ioc in iocs['domains']]))
        if iocs['tools']:
            query_parts.append(f" OR ".join([f"message:{ioc}" for ioc in iocs['tools']]))
        if iocs['commands']:
            query_parts.append(f" OR ".join([f"message:{ioc}" for ioc in iocs['commands']]))
        combined_query = " OR ".join(query_parts)
        if combined_query:
            return combined_query, None, "timesketch_tag", csv_filename
        else:
            console.print("No IOCs found in storage to search in Timesketch.", style="bold yellow")
            return None, None, None, None
    # Handle specific event ID query in the custom event database
    event_id_match = re.search(r'event\s?(\d+)', question, re.IGNORECASE)
    if event_id_match:
        event_id = event_id_match.group(1)
        if event_id in event_descriptions:
            description = event_descriptions[event_id]['description']
            analyst_summary = event_descriptions[event_id]['analyst_summary']
            summary_template = {
                "title": f"Details for Event {event_id}",
                "content": [
                    f"Event ID: {event_id}",
                    f"Description: {description}",
                    f"Analyst Summary: {analyst_summary}"
                ],
                "detailed_analysis": event_descriptions[event_id].get('detailed_analysis', []),
                "suggestions": event_descriptions[event_id].get('suggestions', [])
            }
            return None, summary_template, "summary", csv_filename
        else:
            console.print(f"No description found for Event ID {event_id}.", style="bold red")
            return None, None, None, None
    # Handle keyword search (e.g., "show me all test.exe events")
    keyword_match = re.search(r'show me all (.+) events', question, re.IGNORECASE)
    if keyword_match:
        keyword = keyword_match.group(1).strip()
        query = f"event_identifier:{keyword}"
        return query, None, "timesketch", csv_filename
    # Handle multiple event IDs in Timesketch queries (e.g., show me all 4624 and 4625 events)
    timesketch_event_ids = re.findall(r'\b\d+\b', question)
    if timesketch_event_ids:
        query = " OR ".join([f"event_identifier:{eid}" for eid in timesketch_event_ids])
        return query, None, "timesketch", csv_filename
    # Look for a predefined question match
    matched_question = match_question(question)
    if matched_question:
        if "summary" in question.lower():
            return matched_question['query'], matched_question['summary_template'], "summary", csv_filename
        return matched_question['query'], matched_question['summary_template'], "timesketch", csv_filename
    # Handle switching between modes
    if "switch to timesketch" in question:
        active_mode = "timesketch"
        return "Switched to Timesketch mode.", None, "info", None
    elif "switch to file" in question:
        active_mode = "file"
        return "Switched to file mode.", None, "info", None
    return None, None, None, None
    
# Function to generate NLG summary and handle Timesketch searches
def search_timesketch_and_tag_iocs(query, csv_filename=None, summary_template=None, action="timesketch"):
    try:
        if query is None:
            console.print("No valid query was generated.", style="bold red")
            if summary_template:
                generate_nlg_summary(pd.DataFrame(), summary_template)
            return
        console.print("Executing single query without chunking", style="bold blue")
        search_obj = search.Search(sketch=sketch)
        search_obj.query_string = query
        search_results = search_obj.table
        events_df = pd.DataFrame(search_results)
        if events_df.empty:
            console.print("No results found.", style="bold yellow")
            if summary_template:
                generate_nlg_summary(pd.DataFrame(), summary_template)
            return
        if csv_filename:
            full_path = os.path.join(export_folder, f"{csv_filename}.csv")
            ensure_directory_exists(full_path)
            try:
                events_df.to_csv(full_path, index=False)
                console.print(f"Results successfully exported to {full_path}", style="bold green")
            except Exception as e:
                console.print(f"Failed to export results to CSV: {e}", style="bold red")
        # Generate NLG summary if needed
        if action == "summary" and summary_template:
            generate_nlg_summary(events_df, summary_template)
        elif action != "summary":
            display(events_df.head(10))
            if summary_template:
                generate_nlg_summary(events_df, summary_template)
    except Exception as e:
        console.print(f"An unexpected error occurred: {e}", style="bold red")
# Codex-specific functions
# Function to process a file hash using Codex
def process_hash(file_hash):
    results = {}
    
    # Get antivirus results
    console.print(f"Retrieving antivirus results for hash: {file_hash}", style="bold blue")
    if cg.av_result(file_hash):
        results['antivirus_results'] = cg.response
        console.print("Antivirus results retrieved successfully.", style="bold green")
    else:
        console.print(f"Error retrieving antivirus results: {cg.error_message}", style="bold red")
    # Get metadata
    console.print(f"Retrieving metadata for hash: {file_hash}", style="bold blue")
    if cg.get_metadata(file_hash):
        results['metadata'] = cg.response
        console.print("Metadata retrieved successfully.", style="bold green")
    else:
        console.print(f"Error retrieving metadata: {cg.error_message}", style="bold red")
    # Display the combined results
    display_results(results)
    
    # Option to export results to a file
    export_to_file = input("Would you like to export the results to a file? (y/n): ").strip().lower()
    if export_to_file == 'y':
        export_results_to_file(file_hash, results)
# Function to send a file to Codex for processing and retrieve the results
def send_file_and_get_report(file_path):
    try:
        with open(file_path, 'rb') as f:
            if cg.send_file_to_process(f):
                console.print("File sent for processing successfully.", style="bold green")
                console.print(f"Response after sending file: {cg.response}", style="bold blue")
            else:
                console.print(f"Error sending file: {cg.error_message}", style="bold red")
                return
    except FileNotFoundError:
        console.print(f"File not found: {file_path}", style="bold red")
        return
    # Attempt to retrieve the file hash from the message or response
    file_hash = None
    if 'file_hash' in cg.response:
        file_hash = cg.response['file_hash']
    elif 'message' in cg.response and 'Already exists' in cg.response['message']:
        file_hash = cg.response['message'].split()[-1]
    
    if not file_hash:
        console.print("Failed to retrieve file hash. Full response:", style="bold red")
        console.print(cg.response, style="bold red")
        return
    # Process the hash
    process_hash(file_hash)
def export_results_to_csv(scan_data, folder_path):
    csv_file = os.path.join(folder_path, 'scan_results.csv')
    flattened_data = pd.json_normalize(scan_data)
    flattened_data.to_csv(csv_file, index=False)
    console.print(f"Scan results exported to CSV at: {csv_file}", style="bold green")
# Function to display results in a readable format
def display_results(results):
    console.print("\n---- Results ----", style="bold blue")
    try:
        console.print(json.dumps(results, indent=4), style="bold cyan")
    except Exception as e:
        console.print(f"Error displaying results: {e}", style="bold red")
# Function to export results to a JSON file
def save_results_to_json(scan_data, folder_path):
    json_file = os.path.join(folder_path, 'scan_results.json')
    try:
        with open(json_file, 'w') as f:
            json.dump(scan_data, f, indent=4)
        console.print(f"Scan results saved to JSON at: {json_file}", style="bold green")
    except Exception as e:
        console.print(f"Error saving results to JSON: {e}", style="bold red")
# Function to export results to a JSON file
def export_results_to_file(identifier, results):
    try:
        output_file = f"results_{identifier}.json"
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=4)
        console.print(f"Results exported successfully to {output_file}", style="bold green")
    except Exception as e:
        console.print(f"Error exporting results to file: {e}", style="bold red")
# Function to save a screenshot
def save_screenshot(scan_data, folder_path):
    screenshot_url = scan_data.get('screenshot')
    if screenshot_url:
        screenshot_file = os.path.join(folder_path, 'screenshot.png')
        try:
            response = requests.get(screenshot_url)
            if response.status_code == 200:
                with open(screenshot_file, 'wb') as f:
                    f.write(response.content)
                console.print(f"Screenshot saved at: {screenshot_file}", style="bold green")
            else:
                console.print(f"Failed to download screenshot: {response.status_code}", style="bold red")
        except Exception as e:
            console.print(f"Error saving screenshot: {e}", style="bold red")
    else:
        console.print("No screenshot URL found in scan data.", style="bold yellow")
# Function to download all responses
def download_all_responses(scan_data, folder_path):
    responses = scan_data.get('data', {}).get('requests', [])
    for i, response in enumerate(responses):
        response_url = response.get('response', {}).get('url')
        if response_url:
            response_file = os.path.join(folder_path, f'response_{i + 1}.txt')
            try:
                resp = requests.get(response_url)
                if resp.status_code == 200:
                    with open(response_file, 'w') as f:
                        f.write(resp.text)
                    console.print(f"Response {i + 1} saved at: {response_file}", style="bold green")
                else:
                    console.print(f"Failed to download response {i + 1}: {resp.status_code}", style="bold red")
            except Exception as e:
                console.print(f"Error downloading response {i + 1}: {e}", style="bold red")
# Function to initiate a URL scan
def scan_url(url):
    headers = {
        'Content-Type': 'application/json',
        'API-Key': API_KEY,
    }
    data = {
        'url': url,
        'visibility': 'public'  # Can also be 'private'
    }
    response = requests.post('https://urlscan.io/api/v1/scan/', headers=headers, json=data)
    
    if response.status_code == 200:
        scan_result = response.json()
        console.print(f"Scan initiated successfully. Scan ID: {scan_result['uuid']}", style="bold green")
        return scan_result['uuid']
    else:
        console.print(f"Error initiating scan: {response.status_code}", style="bold red")
        console.print(response.text, style="bold red")
        return None
def generate_nlg_summary(events_df, summary_template):
    # Print the title
    console.print(f"\n{summary_template['title']}", style="bold magenta")
    # Print the content
    for line in summary_template['content']:
        console.print(line, style="cyan")
    # Print the detailed analysis, if available
    if 'detailed_analysis' in summary_template and summary_template['detailed_analysis']:
        console.print("\nDetailed Analysis:", style="bold blue")
        for detail in summary_template['detailed_analysis']:
            console.print(f"- {detail}", style="yellow")
    # Print the suggestions, if available
    if 'suggestions' in summary_template and summary_template['suggestions']:
        console.print("\nSuggestions:", style="bold blue")
        for suggestion in summary_template['suggestions']:
            console.print(f"- {suggestion}", style="green")
    # Print a summary of event counts if the DataFrame is not empty
    if not events_df.empty:
        if 'event_identifier' in events_df.columns:
            console.print("\nEvent Summary:", style="bold blue")
            event_counts = events_df['event_identifier'].value_counts()
            for event_id, count in event_counts.items():
                console.print(f"Event ID {event_id}: {count} occurrences", style="cyan")
        else:
            console.print("Event identifier not found in the Timesketch results.", style="bold red")
# Function to get scan results
def get_scan_results(scan_id):
    url = f'https://urlscan.io/api/v1/result/{scan_id}/'
    while True:
        response = requests.get(url)
        if response.status_code == 200:
            return response.json()
        elif response.status_code == 404:
            console.print("Scan is still in progress...waiting 10 seconds.", style="bold yellow")
            time.sleep(10)  # Wait and retry
        else:
            console.print(f"Error retrieving scan results: {response.status_code}", style="bold red")
            console.print(response.text, style="bold red")
            return None
# Create and print the "Artificial Digital Analysis Machine" text in bold with customizable font size
def print_adam_description(font_size=14):
    text = Text("Artificial Digital Analysis Machine", style=f"bold magenta")
    console.print(text)
# Updated ASCII art
adam_ascii_art = r"""
 █████╗    ██████╗     █████╗    ███╗   ███╗
██╔══██╗   ██╔══██╗   ██╔══██╗   ████╗ ████║
███████║   ██║  ██║   ███████║   ██╔████╔██║
██╔══██║   ██║  ██║   ██╔══██║   ██║╚██╔╝██║
██║  ██║██╗██████╔╝██╗██║  ██║██╗██║ ╚═╝ ██║
╚═╝  ╚═╝╚═╝╚═════╝ ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝
"""
# Print the ADAM ASCII art
console.print(adam_ascii_art, style="bold cyan")
# Print the "Artificial Digital Analysis Machine" description
print_adam_description(font_size=18)
# Example questions
example_questions = [
    "logon events",
    "logoff events",
    "event id 4624",
    "execution techniques",
    "persistence techniques",
    "show me all the threats detected",
    "show me defender threats",
    "How many events are tagged with execution?",
    "Show me all PowerShell events.",
    "Find all file deletion events.",
    "How many malware detection events occurred?",
    "What is the Windows Defender Malware Detection History Deletion?",
    "show me execution and persistence techniques",
    "show me execution and persistence techniques and export to exec_persis.csv",
    "upload infected.csv",
    "What was the last logon?",
    "How many malware detections were there?",
    "upload report.pdf",
    "upload document.docx",
    "upload spreadsheet.xlsx",
    "switch to timesketch",
    "switch to file",
    "show me the list of indicators and export to indicators.csv",
    "show me the list of tools",
    "show me the list of commands",
    "show me the list of hashes",
    "show me the list of IPs",
    "show me the list of domains",
    "show me the MITRE ATT&CK techniques",
    "show me the list of credential access and persistence techniques",
    "show me all initial access events",
    "show me all defense evasion events",
    "show me all command and control events",
    "IMPORTANT - set export <folderpath>",
    "codex file",
    "codex hash",
    "scan url google.com",
    "scan url yahoo.com",
    "upload <filepath> (stix,sigma,yara,csv) iocs stored in ADAM memory",
    "search for iocs in timesketch and export to iocs.csv",
    "search for iocs in timesketch and tag iocs",
    "generate root cause hypothesis"
]
console.print("\nExample questions you can ask:", style="bold magenta")
for q in example_questions:
    console.print(f"- {q}", style="cyan")
# Enable command history with readline
histfile = "/home/triagex/Downloads/ADAM/.adam_history"  # Path to store the command history
# Try to read the history file if it exists
try:
    readline.read_history_file(histfile)
except FileNotFoundError:
    pass
# Save the history file when the program exits
import atexit
atexit.register(readline.write_history_file, histfile)
# Main loop for asking questions
while True:
    question = input("\nPlease enter your question (or type 'exit' to quit): ")
    if question.lower() == "exit":
        console.print("Exiting the program.", style="bold red")
        break
    elif question.lower().startswith("upload "):
        file_path = question[7:].strip()
        upload_and_analyze_file(file_path)
    else:
        query, summary_template, action, csv_filename = interpret_question(question)
        
        # Debugging print statements
        console.print(f"Query: {query}", style="bold yellow")
        console.print(f"Action: {action}", style="bold yellow")
        console.print(f"CSV Filename: {csv_filename}", style="bold yellow")
        
        if action == "summary" and summary_template:
            generate_nlg_summary(pd.DataFrame(), summary_template)
        elif action == "timesketch_tag":
            search_timesketch_and_tag_iocs(query, csv_filename, summary_template, action)
        elif action == "timesketch":
            # This action only searches Timesketch without tagging
            search_timesketch_and_tag_iocs(query, csv_filename, summary_template, action="timesketch")
# Logging configuration
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')
import os
import re
import json
import pandas as pd
import spacy
import requests
import time
from urllib.parse import urlparse
from timesketch_api_client import client, search
from IPython.display import display
import PyPDF2
import docx
import openpyxl
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer as SumyTokenizer
from sumy.summarizers.lsa import LsaSummarizer
import nltk
from rich.console import Console
from rich.text import Text
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import logging
import readline
import urllib.parse
# Import the CodexGigasInfo class for Codex operations
from codex import CodexGigasInfo
# Initialize Codex
cg = CodexGigasInfo()
# Download the required NLTK data files
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')
# Load spaCy model for NLU
nlp = spacy.load("en_core_web_sm")
# Initialize console for styled text output
console = Console()
# Initialize export folder variable
export_folder = "/home/triagex/Downloads/ADAM"
# File to store all extracted IOCs persistently
iocs_storage_file = '/home/triagex/Downloads/ADAM/iocs_storage.json'
# API Key for URLScan.io
API_KEY = "71999b57-0017-4055-956f-a38e8a8710a7"
# Initialize storage for uploaded data and active mode
uploaded_data = pd.DataFrame()
uploaded_text = ""
active_mode = "timesketch"
# Connect to Timesketch
ts_client = client.TimesketchApi('http://localhost', username='triagex', password='admin')
sketch_id = 4  # Replace with your sketch ID
sketch = ts_client.get_sketch(sketch_id)
# Load predefined questions
def load_predefined_questions(filepath):
    with open(filepath, 'r') as file:
        data = json.load(file)
    return data
predefined_questions = load_predefined_questions('/home/triagex/Downloads/ADAM/predefined_questions.json')
# Load event descriptions
def load_event_descriptions(filepath):
    with open(filepath, 'r') as file:
        event_descriptions = json.load(file)
    return event_descriptions
event_descriptions = load_event_descriptions('/home/triagex/Downloads/ADAM/event_descriptions.json')
# Function to ensure directory exists
def ensure_directory_exists(path):
    directory = os.path.dirname(path)
    if not os.path.exists(directory):
        os.makedirs(directory)
# Function to set the export folder
def set_export_folder(path):
    global export_folder
    if os.path.isdir(path):
        export_folder = path
        console.print(f"Export folder set to: {export_folder}", style="bold green")
    else:
        console.print(f"Invalid folder path: {path}. Please provide a valid folder.", style="bold red")
# Function to find the most relevant predefined question using similarity
def match_question(user_question):
    questions = [q['question'] for q in predefined_questions['questions']]
    vectorizer = TfidfVectorizer().fit_transform(questions + [user_question])
    vectors = vectorizer.toarray()
    cosine_similarities = cosine_similarity(vectors[-1:], vectors[:-1])
    best_match_index = cosine_similarities.argmax()
    best_match_score = cosine_similarities[0][best_match_index]
    if best_match_score > 0.5:  # Threshold for matching
        return predefined_questions['questions'][best_match_index]
    return None
# Function to extract data from the message field in events
def extract_data_from_message(messages, pattern):
    return messages.apply(lambda x: re.findall(pattern, x)).explode().value_counts().to_dict()
# Load IOCs from the persistent storage file
def load_iocs():
    if os.path.exists(iocs_storage_file):
        if os.stat(iocs_storage_file).st_size == 0:
            # If the file is empty, return an empty structure
            return {
                "hashes": [],
                "ips": [],
                "domains": [],
                "tools": [],
                "commands": []
            }
        with open(iocs_storage_file, 'r') as file:
            return json.load(file)
    return {
        "hashes": [],
        "ips": [],
        "domains": [],
        "tools": [],
        "commands": []
    }
# Save IOCs to the persistent storage file
def save_iocs(iocs):
    with open(iocs_storage_file, 'w') as file:
        json.dump(iocs, file, indent=4)
# Add new IOCs to storage and save
def update_iocs(new_iocs):
    iocs = load_iocs()
    for key in iocs.keys():
        iocs[key].extend(new_iocs[key])
        iocs[key] = list(set(iocs[key]))  # Remove duplicates
    save_iocs(iocs)
# Function to update IOCs and save them to the persistent storage
def update_iocs(new_iocs):
    iocs = load_iocs()
    for key in iocs.keys():
        iocs[key].extend(new_iocs[key])
        iocs[key] = list(set(iocs[key]))  # Remove duplicates
    save_iocs(iocs)
# Function to normalize paths
def normalize_path(path):
    # Replace double backslashes with single backslashes
    path = path.replace('\\\\', '\\')
    # Replace user-specific paths with a wildcard using raw string notation
    path = re.sub(r'c:\\users\\[^\\]+\\', r'c:\\users\\*\\', path, flags=re.IGNORECASE)
    return path
# Extract indicators from the text or data
def extract_indicators(text, indicator_type=None):
    indicators = {
        "hashes": [],
        "ips": [],
        "domains": [],
        "tools": [],
        "commands": []
    }
    # Regex patterns for extracting indicators
    hash_pattern = r'\b[A-Fa-f0-9]{64}\b'
    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    domain_pattern = r'\b(?:[a-zA-Z0-9-]+\.)+[a-zA-Z]{2,}\b'
    command_line_pattern = r'"command_line":\s*"([^"]+)"'  # Updated pattern to capture actual command lines
    # Extracting indicators
    indicators["hashes"] = re.findall(hash_pattern, text)
    indicators["ips"] = re.findall(ip_pattern, text)
    indicators["domains"] = re.findall(domain_pattern, text)
    # Extract tools and commands based on known keywords
    tools_keywords = ["AdFind", "Mimikatz", "RClone", "WinRAR", "PowerShell", "Ngrok"]
    for keyword in tools_keywords:
        if keyword.lower() in text.lower():
            indicators["tools"].append(keyword)
    # Extract and normalize command lines
    command_lines = re.findall(command_line_pattern, text)
    for cmd in command_lines:
        normalized_cmd = normalize_path(cmd)
        indicators["commands"].append(normalized_cmd)
    # Extract filenames from paths and normalize them
    file_path_pattern = r'\b[A-Za-z]:\\(?:[^\\/:*?"<>|\r\n]+\\)*[^\\/:*?"<>|\r\n]+\b'
    file_paths = re.findall(file_path_pattern, text)
    for path in file_paths:
        filename = normalize_path(path)  # Normalize the entire path
        indicators["commands"].append(filename)
    # Update persistent IOCs storage
    update_iocs(indicators)
    if indicator_type:
        return {indicator_type: indicators[indicator_type]}
    
    return indicators
    
# Function to extract text from PDF
def extract_text_from_pdf(file_path):
    with open(file_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        text = ""
        for page in reader.pages:
            text += page.extract_text()
    return text
# Function to extract text from DOCX
def extract_text_from_docx(file_path):
    doc = docx.Document(file_path)
    return "\n".join([para.text for para in doc.paragraphs])
# Function to summarize text
def summarize_text(text):
    parser = PlaintextParser.from_string(text, SumyTokenizer("english"))
    summarizer = LsaSummarizer()
    summary = summarizer(parser.document, 6)  # Summarize to 6 sentences
    return " ".join([str(sentence) for sentence in summary])
# Function to upload and analyze a file
def upload_and_analyze_file(file_path):
    global uploaded_data, uploaded_text, active_mode
    
    # Reset previous data
    uploaded_data = pd.DataFrame()
    uploaded_text = ""
    
    # Handle different file types
    if file_path.endswith('.csv'):
        uploaded_data = pd.read_csv(file_path)
        console.print(f"CSV file '{file_path}' uploaded.", style="bold green")
        console.print(uploaded_data.head())
        # Extract IOCs from the single-column CSV and update storage
        extract_and_store_iocs_from_csv(uploaded_data)
    elif file_path.endswith('.json'):
        with open(file_path, 'r') as file:
            data = json.load(file)
            uploaded_data = pd.json_normalize(data)
            uploaded_text = json.dumps(data)
        console.print(f"JSON file '{file_path}' uploaded.", style="bold green")
        iocs = extract_indicators(uploaded_text)
        console.print(iocs, style="bold cyan")
    elif file_path.endswith('.pdf'):
        uploaded_text = extract_text_from_pdf(file_path)
        console.print(f"PDF file '{file_path}' uploaded and summarized.", style="bold green")
    elif file_path.endswith('.docx'):
        uploaded_text = extract_text_from_docx(file_path)
        console.print(f"Word document '{file_path}' uploaded and summarized.", style="bold green")
    elif file_path.endswith('.xlsx'):
        uploaded_data = pd.read_excel(file_path)
        console.print(f"Excel file '{file_path}' uploaded.", style="bold green")
        console.print(uploaded_data.head())
    else:
        console.print("Unsupported file format. Please upload a CSV, JSON, PDF, DOCX, or XLSX file.", style="bold red")
        return
    
    # Set mode to file
    active_mode = "file"
    # Generate and print a summary for text-based files
    if uploaded_text:
        summary = summarize_text(uploaded_text)
        console.print("\nSummary of the uploaded document:\n", style="bold blue")
        console.print(summary, style="cyan")
def create_safe_folder_name(url):
    # Parse the URL to get the domain
    parsed_url = urlparse(url)
    # Use only the netloc (domain) and path, replacing unsafe characters
    safe_name = re.sub(r'[^\w\-_\. ]', '_', parsed_url.netloc + parsed_url.path)
    return safe_name
# Function to identify the root cause and sequence of events based on MITRE ATT&CK techniques
def identify_root_cause(events):
    # Sort events by timestamp
    events.sort(key=lambda x: x.get('timestamp', ''))
    
    # Initialize variables
    root_cause = None
    attack_sequence = []
    initial_compromise_event = None
    
    for event in events:
        # Directly use the MITRE ATT&CK technique from the tags
        technique = event.get('tag', [])
        if technique:
            attack_sequence.append((event, technique))
            
            # Use the first technique as the initial compromise event
            if not initial_compromise_event:
                initial_compromise_event = event
    
    if initial_compromise_event:
        root_cause = f"The attack likely began with a technique related to {initial_compromise_event['tag']} on {initial_compromise_event['timestamp']}."
    
    return root_cause, attack_sequence
# Function to generate and display root cause hypotheses
def generate_root_cause_hypothesis(events):
    root_cause, attack_sequence = identify_root_cause(events)
    
    if root_cause:
        console.print("\nRoot Cause Hypothesis:", style="bold magenta")
        console.print(root_cause, style="cyan")
        
        console.print("\nAttack Sequence:", style="bold magenta")
        for event, technique in attack_sequence:
            console.print(f"{event.get('timestamp', 'Unknown time')}: {event.get('message', 'No message')} (Technique: {', '.join(technique)})", style="cyan")
    else:
        console.print("No root cause identified.", style="bold red")
# Function to query Timesketch for events tagged with MITRE ATT&CK techniques
def query_timesketch_for_mitre_attack():
    query = 'tag:"mitre.attack.*"'  # Adjusted to search for any tag that starts with "mitre.attack"
    search_obj = search.Search(sketch=sketch)
    search_obj.query_string = query
    search_results = search_obj.table
    events_df = pd.DataFrame(search_results)
    if not events_df.empty:
        console.print("Events tagged with MITRE ATT&CK techniques found:", style="bold green")
        console.print(events_df.head(5), style="cyan")
    else:
        console.print("No events tagged with MITRE ATT&CK techniques found in Timesketch.", style="bold red")
    
    return events_df
# Function to interpret the user question and map it to a Timesketch query, Codex query, file query, or URLScan.io query
def interpret_question(question):
    global active_mode, export_folder
    if question.lower().startswith("set export"):
        path = question[10:].strip()
        set_export_folder(path)
        return None, None, "info", None
    csv_filename = None
    if "export to" in question:
        parts = question.split("export to")
        question = parts[0].strip()
        csv_filename = parts[1].strip()
    # Handle Codex file or hash queries
    if "codex file" in question.lower():
        file_path = input("Please enter the full path to the file for Codex analysis: ").strip()
        send_file_and_get_report(file_path)
        return None, None, "codex", None
    elif "codex hash" in question.lower():
        file_hash = input("Please enter the file hash (MD5, SHA1, or SHA256) for Codex analysis: ").strip()
        process_hash(file_hash)
        return None, None, "codex", None
    # Handle URLScan.io queries
    if "scan url" in question.lower():
        url = re.search(r'scan url\s+(\S+)', question, re.IGNORECASE)
        if url:
            url = url.group(1)
            scan_id = scan_url(url)
            if scan_id:
                console.print("Waiting for scan results...", style="bold yellow")
                scan_data = get_scan_results(scan_id)
                if scan_data:
                    folder_name = create_safe_folder_name(url)
                    folder_path = os.path.join('/home/triagex/Downloads/ADAM/url', folder_name)
                    os.makedirs(folder_path, exist_ok=True)
                    display_results(scan_data)
                    export_results_to_csv(scan_data, folder_path)
                    save_results_to_json(scan_data, folder_path)
                    save_screenshot(scan_data, folder_path)
                    download_all_responses(scan_data, folder_path)
            return None, None, "urlscan", None
    # Handle IOC search in Timesketch (with chunking)
    if "search for iocs in timesketch" in question.lower():
        iocs = load_iocs()
        query_parts = []
        if iocs['hashes']:
            query_parts.append(f" OR ".join([f"message:{ioc}" for ioc in iocs['hashes']]))
        if iocs['ips']:
            query_parts.append(f" OR ".join([f"message:{ioc}" for ioc in iocs['ips']]))
        if iocs['domains']:
            query_parts.append(f" OR ".join([f"message:{ioc}" for ioc in iocs['domains']]))
        if iocs['tools']:
            query_parts.append(f" OR ".join([f"message:{ioc}" for ioc in iocs['tools']]))
        if iocs['commands']:
            query_parts.append(f" OR ".join([f"message:{ioc}" for ioc in iocs['commands']]))
        combined_query = " OR ".join(query_parts)
        if combined_query:
            return combined_query, None, "timesketch_tag", csv_filename
        else:
            console.print("No IOCs found in storage to search in Timesketch.", style="bold yellow")
            return None, None, None, None
    # Handle specific event ID query in the custom event database
    event_id_match = re.search(r'event\s?(\d+)', question, re.IGNORECASE)
    if event_id_match:
        event_id = event_id_match.group(1)
        if event_id in event_descriptions:
            description = event_descriptions[event_id]['description']
            analyst_summary = event_descriptions[event_id]['analyst_summary']
            summary_template = {
                "title": f"Details for Event {event_id}",
                "content": [
                    f"Event ID: {event_id}",
                    f"Description: {description}",
                    f"Analyst Summary: {analyst_summary}"
                ],
                "detailed_analysis": event_descriptions[event_id].get('detailed_analysis', []),
                "suggestions": event_descriptions[event_id].get('suggestions', [])
            }
            return None, summary_template, "summary", csv_filename
        else:
            console.print(f"No description found for Event ID {event_id}.", style="bold red")
            return None, None, None, None
    # Handle keyword search (e.g., "show me all test.exe events")
    keyword_match = re.search(r'show me all (.+) events', question, re.IGNORECASE)
    if keyword_match:
        keyword = keyword_match.group(1).strip()
        query = f"event_identifier:{keyword}"
        return query, None, "timesketch", csv_filename
    # Handle multiple event IDs in Timesketch queries (e.g., show me all 4624 and 4625 events)
    timesketch_event_ids = re.findall(r'\b\d+\b', question)
    if timesketch_event_ids:
        query = " OR ".join([f"event_identifier:{eid}" for eid in timesketch_event_ids])
        return query, None, "timesketch", csv_filename
    # Look for a predefined question match
    matched_question = match_question(question)
    if matched_question:
        if "summary" in question.lower():
            return matched_question['query'], matched_question['summary_template'], "summary", csv_filename
        return matched_question['query'], matched_question['summary_template'], "timesketch", csv_filename
    # Handle switching between modes
    if "switch to timesketch" in question:
        active_mode = "timesketch"
        return "Switched to Timesketch mode.", None, "info", None
    elif "switch to file" in question:
        active_mode = "file"
        return "Switched to file mode.", None, "info", None
    return None, None, None, None
    
# Function to generate NLG summary and handle Timesketch searches
def search_timesketch_and_tag_iocs(query, csv_filename=None, summary_template=None, action="timesketch"):
    try:
        if query is None:
            console.print("No valid query was generated.", style="bold red")
            if summary_template:
                generate_nlg_summary(pd.DataFrame(), summary_template)
            return
        console.print("Executing single query without chunking", style="bold blue")
        search_obj = search.Search(sketch=sketch)
        search_obj.query_string = query
        search_results = search_obj.table
        events_df = pd.DataFrame(search_results)
        if events_df.empty:
            console.print("No results found.", style="bold yellow")
            if summary_template:
                generate_nlg_summary(pd.DataFrame(), summary_template)
            return
        if csv_filename:
            full_path = os.path.join(export_folder, f"{csv_filename}.csv")
            ensure_directory_exists(full_path)
            try:
                events_df.to_csv(full_path, index=False)
                console.print(f"Results successfully exported to {full_path}", style="bold green")
            except Exception as e:
                console.print(f"Failed to export results to CSV: {e}", style="bold red")
        # Generate NLG summary if needed
        if action == "summary" and summary_template:
            generate_nlg_summary(events_df, summary_template)
        elif action != "summary":
            display(events_df.head(10))
            if summary_template:
                generate_nlg_summary(events_df, summary_template)
    except Exception as e:
        console.print(f"An unexpected error occurred: {e}", style="bold red")
# Codex-specific functions
# Function to process a file hash using Codex
def process_hash(file_hash):
    results = {}
    
    # Get antivirus results
    console.print(f"Retrieving antivirus results for hash: {file_hash}", style="bold blue")
    if cg.av_result(file_hash):
        results['antivirus_results'] = cg.response
        console.print("Antivirus results retrieved successfully.", style="bold green")
    else:
        console.print(f"Error retrieving antivirus results: {cg.error_message}", style="bold red")
    # Get metadata
    console.print(f"Retrieving metadata for hash: {file_hash}", style="bold blue")
    if cg.get_metadata(file_hash):
        results['metadata'] = cg.response
        console.print("Metadata retrieved successfully.", style="bold green")
    else:
        console.print(f"Error retrieving metadata: {cg.error_message}", style="bold red")
    # Display the combined results
    display_results(results)
    
    # Option to export results to a file
    export_to_file = input("Would you like to export the results to a file? (y/n): ").strip().lower()
    if export_to_file == 'y':
        export_results_to_file(file_hash, results)
# Function to send a file to Codex for processing and retrieve the results
def send_file_and_get_report(file_path):
    try:
        with open(file_path, 'rb') as f:
            if cg.send_file_to_process(f):
                console.print("File sent for processing successfully.", style="bold green")
                console.print(f"Response after sending file: {cg.response}", style="bold blue")
            else:
                console.print(f"Error sending file: {cg.error_message}", style="bold red")
                return
    except FileNotFoundError:
        console.print(f"File not found: {file_path}", style="bold red")
        return
    # Attempt to retrieve the file hash from the message or response
    file_hash = None
    if 'file_hash' in cg.response:
        file_hash = cg.response['file_hash']
    elif 'message' in cg.response and 'Already exists' in cg.response['message']:
        file_hash = cg.response['message'].split()[-1]
    
    if not file_hash:
        console.print("Failed to retrieve file hash. Full response:", style="bold red")
        console.print(cg.response, style="bold red")
        return
    # Process the hash
    process_hash(file_hash)
def export_results_to_csv(scan_data, folder_path):
    csv_file = os.path.join(folder_path, 'scan_results.csv')
    flattened_data = pd.json_normalize(scan_data)
    flattened_data.to_csv(csv_file, index=False)
    console.print(f"Scan results exported to CSV at: {csv_file}", style="bold green")
# Function to display results in a readable format
def display_results(results):
    console.print("\n---- Results ----", style="bold blue")
    try:
        console.print(json.dumps(results, indent=4), style="bold cyan")
    except Exception as e:
        console.print(f"Error displaying results: {e}", style="bold red")
# Function to export results to a JSON file
def save_results_to_json(scan_data, folder_path):
    json_file = os.path.join(folder_path, 'scan_results.json')
    try:
        with open(json_file, 'w') as f:
            json.dump(scan_data, f, indent=4)
        console.print(f"Scan results saved to JSON at: {json_file}", style="bold green")
    except Exception as e:
        console.print(f"Error saving results to JSON: {e}", style="bold red")
# Function to export results to a JSON file
def export_results_to_file(identifier, results):
    try:
        output_file = f"results_{identifier}.json"
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=4)
        console.print(f"Results exported successfully to {output_file}", style="bold green")
    except Exception as e:
        console.print(f"Error exporting results to file: {e}", style="bold red")
# Function to save a screenshot
def save_screenshot(scan_data, folder_path):
    screenshot_url = scan_data.get('screenshot')
    if screenshot_url:
        screenshot_file = os.path.join(folder_path, 'screenshot.png')
        try:
            response = requests.get(screenshot_url)
            if response.status_code == 200:
                with open(screenshot_file, 'wb') as f:
                    f.write(response.content)
                console.print(f"Screenshot saved at: {screenshot_file}", style="bold green")
            else:
                console.print(f"Failed to download screenshot: {response.status_code}", style="bold red")
        except Exception as e:
            console.print(f"Error saving screenshot: {e}", style="bold red")
    else:
        console.print("No screenshot URL found in scan data.", style="bold yellow")
# Function to download all responses
def download_all_responses(scan_data, folder_path):
    responses = scan_data.get('data', {}).get('requests', [])
    for i, response in enumerate(responses):
        response_url = response.get('response', {}).get('url')
        if response_url:
            response_file = os.path.join(folder_path, f'response_{i + 1}.txt')
            try:
                resp = requests.get(response_url)
                if resp.status_code == 200:
                    with open(response_file, 'w') as f:
                        f.write(resp.text)
                    console.print(f"Response {i + 1} saved at: {response_file}", style="bold green")
                else:
                    console.print(f"Failed to download response {i + 1}: {resp.status_code}", style="bold red")
            except Exception as e:
                console.print(f"Error downloading response {i + 1}: {e}", style="bold red")
# Function to initiate a URL scan
def scan_url(url):
    headers = {
        'Content-Type': 'application/json',
        'API-Key': API_KEY,
    }
    data = {
        'url': url,
        'visibility': 'public'  # Can also be 'private'
    }
    response = requests.post('https://urlscan.io/api/v1/scan/', headers=headers, json=data)
    
    if response.status_code == 200:
        scan_result = response.json()
        console.print(f"Scan initiated successfully. Scan ID: {scan_result['uuid']}", style="bold green")
        return scan_result['uuid']
    else:
        console.print(f"Error initiating scan: {response.status_code}", style="bold red")
        console.print(response.text, style="bold red")
        return None
def generate_nlg_summary(events_df, summary_template):
    # Print the title
    console.print(f"\n{summary_template['title']}", style="bold magenta")
    # Print the content
    for line in summary_template['content']:
        console.print(line, style="cyan")
    # Print the detailed analysis, if available
    if 'detailed_analysis' in summary_template and summary_template['detailed_analysis']:
        console.print("\nDetailed Analysis:", style="bold blue")
        for detail in summary_template['detailed_analysis']:
            console.print(f"- {detail}", style="yellow")
    # Print the suggestions, if available
    if 'suggestions' in summary_template and summary_template['suggestions']:
        console.print("\nSuggestions:", style="bold blue")
        for suggestion in summary_template['suggestions']:
            console.print(f"- {suggestion}", style="green")
    # Print a summary of event counts if the DataFrame is not empty
    if not events_df.empty:
        if 'event_identifier' in events_df.columns:
            console.print("\nEvent Summary:", style="bold blue")
            event_counts = events_df['event_identifier'].value_counts()
            for event_id, count in event_counts.items():
                console.print(f"Event ID {event_id}: {count} occurrences", style="cyan")
        else:
            console.print("Event identifier not found in the Timesketch results.", style="bold red")
# Function to get scan results
def get_scan_results(scan_id):
    url = f'https://urlscan.io/api/v1/result/{scan_id}/'
    while True:
        response = requests.get(url)
        if response.status_code == 200:
            return response.json()
        elif response.status_code == 404:
            console.print("Scan is still in progress...waiting 10 seconds.", style="bold yellow")
            time.sleep(10)  # Wait and retry
        else:
            console.print(f"Error retrieving scan results: {response.status_code}", style="bold red")
            console.print(response.text, style="bold red")
            return None
# Create and print the "Artificial Digital Analysis Machine" text in bold with customizable font size
def print_adam_description(font_size=14):
    text = Text("Artificial Digital Analysis Machine", style=f"bold magenta")
    console.print(text)
# Updated ASCII art
adam_ascii_art = r"""
 █████╗    ██████╗     █████╗    ███╗   ███╗
██╔══██╗   ██╔══██╗   ██╔══██╗   ████╗ ████║
███████║   ██║  ██║   ███████║   ██╔████╔██║
██╔══██║   ██║  ██║   ██╔══██║   ██║╚██╔╝██║
██║  ██║██╗██████╔╝██╗██║  ██║██╗██║ ╚═╝ ██║
╚═╝  ╚═╝╚═╝╚═════╝ ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝
"""
# Print the ADAM ASCII art
console.print(adam_ascii_art, style="bold cyan")
# Print the "Artificial Digital Analysis Machine" description
print_adam_description(font_size=18)
# Example questions
example_questions = [
    "logon events",
    "logoff events",
    "event id 4624",
    "execution techniques",
    "persistence techniques",
    "show me all the threats detected",
    "show me defender threats",
    "How many events are tagged with execution?",
    "Show me all PowerShell events.",
    "Find all file deletion events.",
    "How many malware detection events occurred?",
    "What is the Windows Defender Malware Detection History Deletion?",
    "show me execution and persistence techniques",
    "show me execution and persistence techniques and export to exec_persis.csv",
    "upload infected.csv",
    "What was the last logon?",
    "How many malware detections were there?",
    "upload report.pdf",
    "upload document.docx",
    "upload spreadsheet.xlsx",
    "switch to timesketch",
    "switch to file",
    "show me the list of indicators and export to indicators.csv",
    "show me the list of tools",
    "show me the list of commands",
    "show me the list of hashes",
    "show me the list of IPs",
    "show me the list of domains",
    "show me the MITRE ATT&CK techniques",
    "show me the list of credential access and persistence techniques",
    "show me all initial access events",
    "show me all defense evasion events",
    "show me all command and control events",
    "IMPORTANT - set export <folderpath>",
    "codex file",
    "codex hash",
    "scan url google.com",
    "scan url yahoo.com",
    "upload <filepath> (stix,sigma,yara,csv) iocs stored in ADAM memory",
    "search for iocs in timesketch and export to iocs.csv",
    "search for iocs in timesketch and tag iocs",
    "generate root cause hypothesis"
]
console.print("\nExample questions you can ask:", style="bold magenta")
for q in example_questions:
    console.print(f"- {q}", style="cyan")
# Enable command history with readline
histfile = "/home/triagex/Downloads/ADAM/.adam_history"  # Path to store the command history
# Try to read the history file if it exists
try:
    readline.read_history_file(histfile)
except FileNotFoundError:
    pass
# Save the history file when the program exits
import atexit
atexit.register(readline.write_history_file, histfile)
# Main loop for asking questions
while True:
    question = input("\nPlease enter your question (or type 'exit' to quit): ")
    if question.lower() == "exit":
        console.print("Exiting the program.", style="bold red")
        break
    elif question.lower().startswith("upload "):
        file_path = question[7:].strip()
        upload_and_analyze_file(file_path)
    else:
        query, summary_template, action, csv_filename = interpret_question(question)
        
        # Debugging print statements
        console.print(f"Query: {query}", style="bold yellow")
        console.print(f"Action: {action}", style="bold yellow")
        console.print(f"CSV Filename: {csv_filename}", style="bold yellow")
        
        if action == "summary" and summary_template:
            generate_nlg_summary(pd.DataFrame(), summary_template)
        elif action == "timesketch_tag":
            search_timesketch_and_tag_iocs(query, csv_filename, summary_template, action)
        elif action == "timesketch":
            # This action only searches Timesketch without tagging
            search_timesketch_and_tag_iocs(query, csv_filename, summary_template, action="timesketch")
# Logging configuration
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')
exit
search for iocs in timesketch
exit
search for iocs in timesketch
exit
event 4624
show me 4624 events
show me all 4624 events
exit
search for iocs in timesketch
search for 4624 events
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for iocs in timesketch
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for iocs in timesketch
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for all 4625 events
search for all iocs in timesketch
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
search for iocs in timesketch
search for all 4624 events
search for iocs in timesketch
exit
search for iocs in timesketch
upload /home/triagex/Downloads/ADAM/results_5ff465afaabcbf0150d1a3ab2c2e74f3a4426467.json
show me all event 4624
show me 4624
4624
show me 4624
show me all event 4624
show me 4624
show me all event 4624
show me 4624
show me 4624 events
show me 4624 event
show me 4624 events
show me 4624 event
show me 4624 events
codex hash
show me 4624 events
upload /home/triagex/Downloads/ADAM/iocs.csv
search for iocs in timesketch
upload /home/triagex/Downloads/ADAM/iocs.csv
search for iocs in timesketch
upload /home/triagex/Downloads/ADAM/iocs.csv
search for iocs in timesketch
search for iocs in timesketch and tag iocs
akira
show me 4624 events and tag
tag all 4624 events
show me all 4624 events
show me 4624 events
show me 4624 events and tag
tag 4624 events
show me 4624 events
tag 4624 events
search for iocs in timesketch and tag iocs
AKIRA
tag all 4624 events
logon events
show me 4625 events
show me 4624 events
show me 4625 events
tag all 4625 events
logoff events
search for iocs in timesketch and tag iocs
testing
remove tag akira
remove akira tag
tag all 4624 events
logging
remove akira tag
remove logon tag
remove tag testing
remove testing tag
show me execution techniques
show me testing events
show me all execution events
show me all testing events
show me all execution techniques
show me all execution techinques
show me all testing techniques
show me all testing tags
show me all akira tagged events
show all akira tags
show me all akira tagged events
export all tagged events to tagged.csv
show me 4624 events
show me test.exe events
show me test.exe
tag test.exe events
tag 4625 events
tag powershell events
show me powershell events
show me powershell
show me powershell events
show me test.exe events
tag test.exe events
show me 8af282b10fd825dc83d827c1d8d23b53 events
search for iocs in timesketch and tag iocs
malicious
upload /home/triagex/Downloads/ADAM/iocs.csv
search for iocs in timesketch and tag iocs
malicious
exit
search for iocs in timesketch and tag iocs
search for iocs in timesketch and tag iocs from csv
build a timeline of events based on the mitre attack framework
exit
build a timeline of events based on the mitre attack framework
exit
run sigma hunt
exit
run sigma hunt
exit
run sigma hunt
eit
exit
run sigma hunt
exit
generate root cause hypotheis
generate root cause hypothesis
exi
exit
event 4624
4624
event id 4624
show me all 4624 events
exit
event 4624
exit
event 4624
event 4625
exit
what is akira
What is T1548.004
exit
what is Akira
what is akira
what is cutting edge
exit
what is akira
exit
what is akira
What is Akira
exit
what is akira
exit
what is akira
What is Akira
exiit
exit
what is Akira
what is akira
exit
what is akira
exit
what is akira
what is moon
what is moonwind
exit
what is akira
exit
what is akira
exit
what is akira
exi
exit
what is akira
exiy
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exi
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
what is moonwind
exit
what is T1490
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
what is T1490
exit
what is akira
what is T1490
exit
what is T1490
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exi
exit
what is akira
exxit
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
Please enter your question (or type 'exit' to quit): what is akira
Name: Akira
Description: [Akira](https://attack.mitre.org/software/S1129) ransomware, written in C++, is most prominently (but not exclusively) associated with the a 
ransomware-as-a-service entity [Akira](https://attack.mitre.org/groups/G1024).(Citation: Kersten Akira 2023)
External ID: S1129
Name: Akira
Description: [Akira](https://attack.mitre.org/groups/G1024) is a ransomware variant and ransomware deployment entity active since at least March 2023.(Citation: Arctic 
Wolf Akira 2023) [Akira](https://attack.mitre.org/groups/G1024) uses compromised credentials to access single-factor external access mechanisms such as VPNs for initial 
access, then various publicly-available tools and techniques for lateral movement.(Citation: Arctic Wolf Akira 2023)(Citation: Secureworks GOLD SAHARA) 
[Akira](https://attack.mitre.org/groups/G1024) operations are associated with "double extortion" ransomware activity, where data is exfiltrated from victim environments 
prior to encryption, with threats to publish files if a ransom is not paid. Technical analysis of [Akira](https://attack.mitre.org/software/S1129) ransomware indicates 
multiple overlaps with and similarities to [Conti](https://attack.mitre.org/software/S0575) malware.(Citation: BushidoToken Akira 2023)
External ID: G1024
Please enter your question (or type 'exit' to quit): exit
Exiting the program.
triagex@triagex-virtual-machine:~/Downloads/ADAM$ python3 adam_backup_testing.py 
Uploading Mitre CTI files to ADAM... Files loaded: 20252
Name: Akira
Description: [Akira](https://attack.mitre.org/software/S1129) ransomware, written in C++, is most prominently (but not exclusively) associated with the a 
ransomware-as-a-service entity [Akira](https://attack.mitre.org/groups/G1024).(Citation: Kersten Akira 2023)
External References: [S1129](https://attack.mitre.org/software/S1129), [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: malware
ID: malware--6f6b2353-4b39-40ce-9d6d-d00b7a61e656
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) will exfiltrate victim data using applications such as 
[Rclone](https://attack.mitre.org/software/S1040).(Citation: Secureworks GOLD SAHARA)
External References: [N/A](https://www.secureworks.com/research/threat-profiles/gold-sahara)
Object Type: relationship
ID: relationship--036b0dfd-5d52-4b10-9951-8d967fc8df3c
Name: N/A
Description: [Akira](https://attack.mitre.org/software/S1129) examines files prior to encryption to determine if they meet requirements for encryption and can be 
encrypted by the ransomware. These checks are performed through native Windows functions such as <code>GetFileAttributesW</code>.(Citation: Kersten Akira 2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--079b3956-d020-4b9d-a230-e43b391e261f
Name: N/A
Description: [Akira](https://attack.mitre.org/software/S1129) uses the <code>GetSystemInfo</code> Windows function to determine the number of processors on a victim 
machine.(Citation: Kersten Akira 2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--0d853746-8d17-4d1a-be4a-6133e39a6c84
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) has accessed and downloaded information stored in SharePoint instances as part of data gathering and 
exfiltration activity.(Citation: Secureworks GOLD SAHARA)
External References: [N/A](https://www.secureworks.com/research/threat-profiles/gold-sahara)
Object Type: relationship
ID: relationship--0e472133-290f-42f3-9dd3-104b7ba978d2
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) deletes administrator accounts in victim networks prior to encryption.(Citation: Secureworks GOLD SAHARA)
External References: [N/A](https://www.secureworks.com/research/threat-profiles/gold-sahara)
Object Type: relationship
ID: relationship--21247679-6bd8-43dc-921b-530d255d1d6c
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) uses the built-in [Nltest](https://attack.mitre.org/software/S0359) utility or tools such as 
[AdFind](https://attack.mitre.org/software/S0552) to enumerate Active Directory trusts in victim environments.(Citation: Arctic Wolf Akira 2023) 
External References: [N/A](https://arcticwolf.com/resources/blog/conti-and-akira-chained-together/)
Object Type: relationship
ID: relationship--35d6d4f5-3c25-47bb-97d9-67d1e004d180
Name: N/A
Description: (Citation: Arctic Wolf Akira 2023)
External References: [N/A](https://arcticwolf.com/resources/blog/conti-and-akira-chained-together/)
Object Type: relationship
ID: relationship--3fff8382-175d-44ce-b430-ae32930817ec
Name: N/A
Description: [Akira](https://attack.mitre.org/software/S1129) will execute PowerShell commands to delete system volume shadow copies.(Citation: Kersten Akira 2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--424f1b60-9dbb-4022-8789-5338c7e1caa0
Name: N/A
Description: [Akira](https://attack.mitre.org/software/S1129) will leverage COM objects accessed through WMI during execution to evade detection.(Citation: Kersten Akira 
2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--44271618-cc52-45a9-9799-e9665b73cfc2
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) uses valid account information to remotely access victim networks, such as VPN credentials.(Citation: 
Secureworks GOLD SAHARA)(Citation: Arctic Wolf Akira 2023)
External References: [N/A](https://www.secureworks.com/research/threat-profiles/gold-sahara), 
[N/A](https://arcticwolf.com/resources/blog/conti-and-akira-chained-together/)
Object Type: relationship
ID: relationship--536ce093-85f3-4e80-9f61-4fa3739e874a
Name: N/A
Description: (Citation: Arctic Wolf Akira 2023) 
External References: [N/A](https://arcticwolf.com/resources/blog/conti-and-akira-chained-together/)
Object Type: relationship
ID: relationship--5b8fab1d-c033-487b-a9c5-c699a0f11907
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) uses software such as Advanced IP Scanner and MASSCAN to identify remote hosts within victim 
networks.(Citation: Arctic Wolf Akira 2023)
External References: [N/A](https://arcticwolf.com/resources/blog/conti-and-akira-chained-together/)
Object Type: relationship
ID: relationship--5d23f25a-d98a-47a6-8da7-86e8a73c3407
Name: N/A
Description: [Akira](https://attack.mitre.org/software/S1129) executes from the Windows command line and can take various arguments for execution.(Citation: Kersten Akira
2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--664df356-e939-4705-9e94-85721d5a53ef
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) engages in double-extortion ransomware, exfiltrating files then encrypting them, in order to prompt victims to
pay a ransom.(Citation: BushidoToken Akira 2023)
External References: [N/A](https://blog.bushidotoken.net/2023/09/tracking-adversaries-akira-another.html)
Object Type: relationship
ID: relationship--7e57b3e4-207c-4ef0-89bb-dc062fcad62e
Name: N/A
Description: [Akira](https://attack.mitre.org/software/S1129) can identify remote file shares for encryption.(Citation: Kersten Akira 2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--7ef41aaa-7625-4168-b040-92972454b8fb
Name: N/A
Description: (Citation: Arctic Wolf Akira 2023)
External References: [N/A](https://arcticwolf.com/resources/blog/conti-and-akira-chained-together/)
Object Type: relationship
ID: relationship--9092578b-593b-4a4b-ba3f-2bfeed172567
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) encrypts files in victim environments as part of ransomware operations.(Citation: BushidoToken Akira 2023)
External References: [N/A](https://blog.bushidotoken.net/2023/09/tracking-adversaries-akira-another.html)
Object Type: relationship
ID: relationship--9ed66c72-199a-47d7-8bdd-95c34a370d33
Name: N/A
Description: [Akira](https://attack.mitre.org/software/S1129) executes native Windows functions such as <code>GetFileAttributesW</code> and `GetSystemInfo`.(Citation: 
Kersten Akira 2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--a4daf827-18c5-4866-86da-97bc8c77ca99
Name: N/A
Description: [Akira](https://attack.mitre.org/software/S1129) will delete system volume shadow copies via PowerShell commands.(Citation: Kersten Akira 2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--aeb5cdda-6344-4048-9b41-a0e0e75ef099
Name: N/A
Description: (Citation: Kersten Akira 2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--b240e6ba-9c38-4a6b-a4e9-30c07736711b
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) uses compromised VPN accounts for initial access to victim networks.(Citation: Secureworks GOLD SAHARA)
External References: [N/A](https://www.secureworks.com/research/threat-profiles/gold-sahara)
Object Type: relationship
ID: relationship--d2825a04-d5c4-4598-aa3d-cb72cfe74ac4
Name: N/A
Description: [Akira](https://attack.mitre.org/software/S1129) verifies the deletion of volume shadow copies by checking for the existence of the process ID related to the
process created to delete these items.(Citation: Kersten Akira 2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--d33b14b1-7501-4bb3-af8c-3e2202fa572f
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) uses legitimate utilities such as AnyDesk and PuTTy for maintaining remote access to victim 
environments.(Citation: Secureworks GOLD SAHARA)(Citation: Arctic Wolf Akira 2023)
External References: [N/A](https://www.secureworks.com/research/threat-profiles/gold-sahara), 
[N/A](https://arcticwolf.com/resources/blog/conti-and-akira-chained-together/)
Object Type: relationship
ID: relationship--e514f2a1-c3ae-403d-bbf4-8b72e29c49f1
Name: N/A
Description: (Citation: Arctic Wolf Akira 2023)
External References: [N/A](https://arcticwolf.com/resources/blog/conti-and-akira-chained-together/)
Object Type: relationship
ID: relationship--e5328a4e-b37a-4020-b242-ea6c60605e02
Name: N/A
Description: (Citation: Arctic Wolf Akira 2023)
External References: [N/A](https://arcticwolf.com/resources/blog/conti-and-akira-chained-together/)
Object Type: relationship
ID: relationship--e59eafd8-6579-4ca0-b357-6df989142449
Name: N/A
Description: [Akira](https://attack.mitre.org/groups/G1024) uses utilities such as WinRAR to archive data prior to exfiltration.(Citation: Secureworks GOLD SAHARA)
External References: [N/A](https://www.secureworks.com/research/threat-profiles/gold-sahara)
Object Type: relationship
ID: relationship--f7416b2f-b3b3-4fc4-a463-05ae302a6b24
Name: N/A
Description: [Akira](https://attack.mitre.org/software/S1129) encrypts victim filesystems for financial extortion purposes.(Citation: Kersten Akira 2023)
External References: [N/A](https://www.trellix.com/blogs/research/akira-ransomware/)
Object Type: relationship
ID: relationship--fde26c5e-7f17-4119-b5d1-86a7fbe4a184
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
# Function to handle dynamic queries like 'What is Akira' and exclude incomplete or duplicate entries
def handle_search_query(query):
    search_term_match = re.search(r'what is (.+)', query, re.IGNORECASE)
    
    if search_term_match:
        search_term = search_term_match.group(1).strip()
        results = search_attack_data(search_term, attack_data)  # Search dynamically based on the query
        
        # Use a set to track already displayed IDs and avoid duplicates
        seen_ids = set()
        
        if results:
            # Display each result individually and filter out empty or incomplete results
            for result in results:
                # Only display results with a valid description, external references, and object type
                if (result['description'] and result['external_ids'] and result['type'] != 'N/A'):
                    # Avoid duplicates by checking the unique ID
                    if result['id'] not in seen_ids:
                        seen_ids.add(result['id'])  # Track this ID as seen
                        console.print(f"\nName: {result['name']}", style="bold magenta")
                        console.print(f"Description: {result['description']}", style="cyan")
                        if result.get('external_ids'):
                            console.print(f"External References: {', '.join(result['external_ids'])}", style="bold blue")
                        # Display object type and ID
                        console.print(f"Object Type: {result['type']}", style="bold green")
                        console.print(f"ID: {result['id']}", style="bold white")
        else:
exit
what is akira
exi
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
eixt
exit
eixt
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is akira
exit
what is lockbit
what is blackcat
event 4624
search for 4624 events
show me 4624 events
show me https:
show me urls
show me powershell events
exit
show me defender threats
logon events
exot
exit
logon events
show me 4624 events
4624 events
exit
logon events
showe 4624 events
exit
show me powershell events
show me akira events
show me akira
show me akira and export to akira.csv
exit
show me akira
show me akira and export to akira.csv
exit
show me akira
show me akira events
show me akira and export
show me akira and export to akira.csv
exit
show me akira and export to akira.csv
show me akira export to akira.csv
exi
exit
show me akira and export to akira.csv
exit
show me powershell events
show me powershell
show me akira
tag akira events
tage akira
tag akira
exit
what is akira
show me 4624
show me all 4624 events
show me akira
show me akira events
show me akira events and tag
tag akira events
akira
export all tagged events to tagg.csv
show me defender threats
show me defender
show me 4624
show me winscp
show me winscp events
show me https:// events
show me htt events
show me http* events
show me http://www.*
show me http://www.* events
show me URL events
exit
upload /home/triagex/Downloads/full.txt
upload /home/triagex/Downloads/full.csv
exit
what is ef8b4e8c58ad596b28d6475370c36718b4d80e6c34cc27ff765fd2868efc64f6
exit
what is ef8b4e8c58ad596b28d6475370c36718b4d80e6c34cc27ff765fd2868efc64f6
exit
what is ef8b4e8c58ad596b28d6475370c36718b4d80e6c34cc27ff765fd2868efc64f6
exit
eexit
exit
what is filename razrusheniye.bin
what is hash 0c733af349eb78d6db9adaabe29557488cf6e0b75539f37d70aefb0142b023e9
what is 0c733af349eb78d6db9adaabe29557488cf6e0b75539f37d70aefb0142b023e9
exit
what is 0c733af349eb78d6db9adaabe29557488cf6e0b75539f37d70aefb0142b023e9
what is hash 0c733af349eb78d6db9adaabe29557488cf6e0b75539f37d70aefb0142b023e9
what is filename razrusheniye.bin
exit
what is filename razrusheniye.bin
what is hash 0c733af349eb78d6db9adaabe29557488cf6e0b75539f37d70aefb0142b023e9
what is 0c733af349eb78d6db9adaabe29557488cf6e0b75539f37d70aefb0142b023e9
what is razrusheniye.bin
exit
what is razrusheniye.bin
what is 0c733af349eb78d6db9adaabe29557488cf6e0b75539f37d70aefb0142b023e9
what is hash 0c733af349eb78d6db9adaabe29557488cf6e0b75539f37d70aefb0142b023e9
what is c2a242612468814e2e951e4db3762059
what is akira
what is c2a242612468814e2e951e4db3762059
what is RemcosRAT
what is moon
what is lockbit
what is locky
exit
search for all akira iocs
search for all akira
exit
search for all akira
search for all akira iocs
search for all Akira
exit
what is akira
exit
generate root cause hypothesis
exit
generate root cause hypothesis
remove akira tag
remove akira tags
remove all akira tags
exit
tag all akira events 
akira123
remove all akira123 tags
remove akira123 tags
exit
remove akira123 tags
exit
remove akira123 tags
exit
remove akira123 tags
exit
remove akira123 tags
exit
remove akira123 tags
exit
remove akira tags
exit
what was the last logon
exit
show me all initial access events
exit
show me all initial access events
exit
show me all initial access events
exit
show me all initial access events
show me the full timeline of events
show me all persistence events
exit
import zircolite data
show me all initial access events
exit
show me all initial access events
exit
show me all initial access events
exit
show me all initial access events
exi
texit
exit
show me all initial access events
import zircolite data
show me all initial access events
import zircolite data
show me all initial access events
import zircolite data
exit
import zircolite data
exit
show me all initial access events
import zircolite data
show me all initial access events
import zircolite data
show me all initial access events
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
show 4624 events
exit
show 4624 events
exit
show 4624 events
show me all initial access events
import zircolite data
show me all initial access events
show me all initial access
exit
show me initial access techniques
show me initial access events
exit
show me initial access events
exit
show me initial access events
show me Lateral Movement events
show me lateral movement events
show me persistence events
exit
show me initial access events
show me persistence events
show me initial access events
exit
show me initial access events
show me persistence events
exit
show me initial access events
show me persistence events
exit
show me persistence events
exit
show me persistence events
show me initial access events
exot
exit
show me initial access events
exit
show me initial access events
show me persistence events
exit
show me initial access events
show me persistence events
exit
show me persistence events
exit
show me persistence events
show me initial access events
exit
show me initial access events
show me persistence events
exit
show me persistence events
exit
show me initial access events
show me persistence events
exi
exit
show me initial access events
show me persistence events
exit
show me initial access events
show me persistence events
show me all 4625 events
show me all 4625 
show me all 4624
exit
show me persistence events
exit
tag 4624 events
logon
show me initial access events
show me persistence events
show me initial access events
exit
show me initial access events
exit
import zircolite data
exit
import zircolite data
exit
show me initial access
exit
show me all initial access events
show me initial access
show me all initial access events
exit
show me all initial access events
show me initial access events
show me persistence
show me persistence events
show me powershell events
show me service events
exit
show me service events
show me persistence events
exit
show me persistence events
show me powershell events
exit
show me powershell events
exit
show me powershell events
exit
show me powershell events
exit
show me powershell events
exit
show me powershell events
exit
show me powershell events
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
exit
import zircolite data
show me initial access events
show me persistence events
show me powershell events
show me execution events
exit
show me execution events
show me persistence events
exit
show me powershell events
show me offlinesam events
tag offlinesam events
offlinesam
remove offlinesam tags
exit
generate zircolite report
exit
import iocs.csv
import iocs
upload /home/triagex/Downloads/ADAM/iocs.csv
search for iocs in timesketch
search for iocs in timesketch and tag iocs
malicious
remove malicious tag
exit
remove malicious tag
exit
show 4624 events
exit
show 4624 events
show me *akira events
show me *akira events and export to akiranewnew.csv
exit
what is akira
exit
can you show me all 4624 events
show me all 4624 events
I'm good what can you do
what can you do
how can you assist met
Explain Akira
show me 4624 events
help
show me all 4624 events
bye
explain akira
what is akira
help
bye
show me 4624 events
show me all 4624 events
tag all 4624 events
bye
show me 4624 events
show me all 4624 events
show me 4624 events
show me all 4624 events
bye\
show me 4624 events
show me all 4624 events
what is akira
exit
show me all logon events?
show me all logon events
codex hash
import zircolite data
bye
Can you show me all 4624 events?
can you show me all logon events
can you show me all4624  logon events
what is akira
explain akira
bye
Explain Akira
Show me all 4624 events
show me all logon events
bye
show me all 4624 events
Show me 4624 evetns
Show me 4624 evnts
show me all logon events
show me all 4624 events
bye
show me 4624 events
show me all logon events
show me all 4624 events
exit
show me all 4624 events
show me 4624 events
show me akira events
exit
show me 4624 events
exit
show me 4624 events
exit
show me 4624 events
what is akira
exit
show all .akira events
shoe all .akira
show all akira
show all 4624 events
show all akira events
exit
show me all powershell events
show me all akira evens
show me powershell events
show me akira events
show me .akira events
remove akira tag
remove tag
exit
remove akira tag
remove tag
exit
remove akira tag
exit
tag akira events
remove akira tag
exit
remove akira tag
exit
remove akira tag
exit
remove IOC match tag
remove IOC Match tag
remove IOC_Match tag
exit
remove IOC Match tag
remove IOC_Match tag
exit
remove IOC_Match tag
exit
